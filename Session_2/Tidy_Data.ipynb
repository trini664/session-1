{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84282db",
   "metadata": {},
   "source": [
    "### Tidy Data\n",
    "\n",
    "Good practice is to import the necessary libraries at the start of your notebook/script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba089e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6afc834f",
   "metadata": {},
   "source": [
    "Getting your data into this format requires some upfront work, but that work pays off in the long term. Once you have tidy data and pandas data frames, you will spend much less time manipulating data from one representation to another, allowing you to spend more time on the analytic questions at hand.\n",
    "\n",
    "Instead of using a csv file, we can also connet to datasets via a URL and then create a dataframe using `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://github.com/byuidatascience/data4python4ds/raw/master/data-raw/\" # base URL for datasets\n",
    "table1 = pd.read_csv(\"{}table1/table1.csv\".format(base_url)) # read table1 dataset\n",
    "table2 = pd.read_csv(\"{}table2/table2.csv\".format(base_url)) # read table2 dataset\n",
    "table3 = pd.read_csv(\"{}table3/table3.csv\".format(base_url)) # read table3 dataset\n",
    "table4a = pd.read_csv(\"{}table4a/table4a.csv\".format(base_url)) # read table4a dataset\n",
    "table4b = pd.read_csv(\"{}table4b/table4b.csv\".format(base_url)) # read table4b dataset\n",
    "table5 = pd.read_csv(\"{}table5/table5.csv\".format(base_url), dtype = 'object') # read table5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42952363",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Table 1\")\n",
    "display(table1)\n",
    "\n",
    "print(\"### Table 2\")\n",
    "display(table2)\n",
    "\n",
    "print(\"### Table 3\")\n",
    "display(table3)\n",
    "\n",
    "print(\"### Table 4a\")\n",
    "display(table4a)\n",
    "\n",
    "print(\"### Table 4b\")\n",
    "display(table4b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea209c",
   "metadata": {},
   "source": [
    "These are all representations of the same underlying data, but they are not equally easy to use. One dataset, the tidy dataset, will be much easier to work with.\n",
    "\n",
    "There are three interrelated rules which make a dataset tidy:\n",
    "\n",
    "**1. Each variable must have its own column.**\n",
    "\n",
    "**2. Each observation must have its own row.**\n",
    "\n",
    "**3. Each value must have its own cell.**\n",
    "\n",
    "![GitHub Codespaces](tidy_data.png)\n",
    "\n",
    "In this example, only table1 is tidy. It’s the only representation where each column is a variable.\n",
    "\n",
    "Why ensure that your data is tidy? There are two main advantages:\n",
    "\n",
    "1. There’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity.\n",
    "\n",
    "2. There’s a specific advantage to placing variables in columns because it allows `Pandas’` and `NumPy’s` vectorised nature to shine. As you learned in `assign` and `aggregate` functions, most built-in functions work with vectors of values. That makes transforming tidy data feel particularly natural.\n",
    "\n",
    "`Pandas` work well with tidy data. Here are a couple of small examples showing how you might work with table1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31e991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85ba93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae983c47",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "\n",
    "Untidy data will suffer from one of two common problems:\n",
    "\n",
    "- One variable might be spread across multiple columns.\n",
    "\n",
    "- One observation might be scattered across multiple rows.\n",
    "\n",
    "Typically a dataset will only suffer from one of these problems; it’ll only suffer from both if you’re really unlucky! To fix these problems, you’ll need two functions in pandas: `melt()`, `pivot()`, and `pivot_table()`. There are two additional functions called `stack()` and `unstack()` that use multi-index columns and rows.\n",
    "\n",
    "**1. Pivoting longer `.melt()`** - Sometimes some of the column names are not names of variables, but values of a variable. To tidy a dataset like this, we need to stack the offending columns into a new pair of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11baa03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9c59283",
   "metadata": {},
   "source": [
    "To tidy a dataset like this, we need to stack the offending columns into a new pair of variables. To describe that operation we need three parameters:\n",
    "\n",
    " - The set of columns whose names are identifier variables, not values. In this example, `country` is the identifier column and the value columns are `1999` and `2000`.\n",
    "\n",
    "- The name of the variable to move the column names to. Here it is `year`.\n",
    "\n",
    "- The name of the variable to move the column values to. Here it’s `cases`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454eb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245ab339",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Use `.melt()` to tidy table4b in a similar fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352d3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14ae6a2e",
   "metadata": {},
   "source": [
    "**2. Pivoting wider `.pivot()`** - is the opposite of `melt()`. You use it when an observation is scattered across multiple rows. For example, take table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ec4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f5d4459",
   "metadata": {},
   "source": [
    "To tidy this up, we first analyse the representation in similar way to `melt()`. This time, however, we only need two parameters:\n",
    "\n",
    "The column to take variable names from. Here, it’s `type`.\n",
    "\n",
    "The column to take values from. Here it’s `count`.\n",
    "\n",
    "Depending on the index, we will need to use either `pivot()` or `pivot_table()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b2865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a2e7f36",
   "metadata": {},
   "source": [
    "Strict reshaping → requires that the combination of `index` + `columns` is unique.\n",
    "\n",
    "If duplicates exist (e.g., if table2 had two rows for Afghanistan–1999–cases), `.pivot()` will throw an error, as we saw.\n",
    "\n",
    "Let's create a dummy table and see what this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f55853",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"country\": [\"Afghanistan\",\"Afghanistan\",\"Afghanistan\",\"Afghanistan\",\"Brazil\",\"Brazil\"],\n",
    "    \"year\":    [1999,1999,1999,1999,1999,1999],\n",
    "    \"type\":    [\"cases\",\"cases\",\"population\",\"population\",\"cases\",\"population\"],\n",
    "    \"count\":   [745,750,19987071,19987071,37737,172006362]\n",
    "}\n",
    "\n",
    "table2a_example = pd.DataFrame(data)\n",
    "table2a_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc512a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c64b8890",
   "metadata": {},
   "source": [
    "By default, the resultant values will be the average of the replicates, we can take care of this by explicitly stating what summary statistic we would like to see using `aggfunc=''`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d96f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f5e0fca",
   "metadata": {},
   "source": [
    "#### Split\n",
    "\n",
    "`str.split()` pulls apart one column into multiple columns, by splitting wherever a separator character appears. Take table3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80a349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e6afbce",
   "metadata": {},
   "source": [
    "The rate column contains both cases and population variables, and we need to split it into two variables. `str.split()` takes the name of the column to split. The names of the columns to separate into can be names using `rename()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec9179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d478cc2",
   "metadata": {},
   "source": [
    "#### Unite\n",
    "\n",
    "For two string series the inverse of `str.split()` can be done with `+`: it combines multiple columns into a single column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b794d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b972ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c432d8",
   "metadata": {},
   "source": [
    "#### Exercise 1: From Long to Wide\n",
    "\n",
    "Task: \n",
    "\n",
    "`ukbabynames` contains a listing of UK baby names occurring more than three times per year\n",
    "between 1974 and 2020\n",
    "\n",
    "The dataset contains columns like `year`, `sex`, `name`, and `n`.\n",
    "\n",
    "Use `.pivot()` or `.pivot_table()` **(recall the unique index!)** to find the total number of babies born by sex in each year.\n",
    "\n",
    "Rows should be years, columns should be sex (M / F), and values should be the sum of counts.\n",
    "\n",
    "**Challenge - calculate the percent of babies who are female using your now tidy dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset as gapminder using pd.read_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265869f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b02eba",
   "metadata": {},
   "source": [
    "#### Exercise 2: From Wide to Long\n",
    "\n",
    "WHO Tuberculosis Data\n",
    "\n",
    "This dataset comes from the World Health Organization (WHO) and records the number of **tuberculosis (TB) cases** reported by different countries, broken down by sex and age group.\n",
    "\n",
    "- **country, iso2, iso3**: identifiers for each country (name and ISO codes).\n",
    "- **year**: the year of observation.\n",
    "- **new_sp_m014, new_sp_m1524, …**: the number of new TB cases, where the code describes the **type of case**, the **sex**, and the **age group**.\n",
    "  - Example: `new_sp_m014` = new cases, sputum positive (`sp`), male (`m`), ages 0–14 (`014`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc4f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238abfd0",
   "metadata": {},
   "source": [
    "#### Exercise: Reshape WHO Tuberculosis Data\n",
    "\n",
    "The WHO dataset contains TB cases reported by country and year. Each combination of **type**, **sex**, and **age group** is stored as a separate column (`new_sp_m014`, `new_sp_f1524`, etc.), which makes the dataset **wide**.\n",
    "\n",
    "Your task:  \n",
    "1. Use `pd.melt()` to convert columns 5 through 60 into **two new columns**:  \n",
    "   - `tb_codes` → the original variable name (e.g., `new_sp_m014`).  \n",
    "   - `n` → the number of TB cases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6892984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "236825bb",
   "metadata": {},
   "source": [
    "2. Clean the new tidy dataframe so it does not have missing `missing values` in the `n` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cca722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1873c79b",
   "metadata": {},
   "source": [
    "### All Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
